ğŸ§  Projeto de Pipeline de Machine Learning com API Flask
ğŸ“Š 1. Diagrama de Pipeline
mermaid
Copiar
Editar
flowchart TD
    A[ğŸ“¥ IngestÃ£o de Dados (Web Scraping)] --> B[ğŸ—‚ï¸ Armazenamento CSV]
    B --> C[ğŸ§¹ PrÃ©-processamento & UnificaÃ§Ã£o (Pandas)]
    C --> D[ğŸš€ API Flask]
    D --> E[ğŸŒ Consumo por Frontend, Cientistas de Dados, Apps]
    C --> F[ğŸ¤– Modelo de ML (Treinamento/PrediÃ§Ã£o)]
    F --> D
ğŸ§¾ 2. DescriÃ§Ã£o do Pipeline
ğŸ“¥ IngestÃ£o
Web scraping coleta dados de livros e salva arquivos .csv em exports/csv/.

ğŸ”„ Processamento
Script unifica e prÃ©-processa os CSVs, gerando tabela_unificada.csv.

Trata tipos, valores ausentes e faz encoding de variÃ¡veis categÃ³ricas.

ğŸš€ API
A API Flask serve endpoints RESTful para:

ğŸ” Consulta e busca

ğŸ“Š EstatÃ­sticas

ğŸ” AutenticaÃ§Ã£o (JWT)

ğŸ¤– PrediÃ§Ã£o com modelo ML

ğŸ¤– Machine Learning
Modelo RandomForest Ã© treinado para prever o rating dos livros.

Exposto via endpoint: /api/v1/ml/predictions.

ğŸŒ Consumo
Cientistas de dados, aplicaÃ§Ãµes web/mobile e dashboards podem consumir a API para anÃ¡lises, visualizaÃ§Ãµes ou automaÃ§Ãµes.

ğŸ—ï¸ 3. Arquitetura para Escalabilidade
ğŸ§© SeparaÃ§Ã£o de responsabilidades
MÃ³dulos independentes: scraping, processamento, API, ML.

FÃ¡cil de escalar e manter.

ğŸ—ƒï¸ PersistÃªncia
CSVs como intermediÃ¡rios (com possibilidade de migraÃ§Ã£o para PostgreSQL/MongoDB).

Modelos versionados em disco (pode migrar para S3, MLflow, etc).

âš™ï¸ API Stateless
Flask pode ser servido por Gunicorn/UWSGI atrÃ¡s de um Nginx.

EscalÃ¡vel horizontalmente (Docker, Kubernetes).

ğŸ§  ML como ServiÃ§o
Modelo ML pode ser exposto como microserviÃ§o (FastAPI, BentoML).

Permite re-treinamento/versionamento independente.

ğŸ‘¨â€ğŸ”¬ 4. CenÃ¡rio de Uso para Cientistas de Dados/ML
ğŸ“‚ Acesso aos Dados
Endpoints:

/api/v1/ml/features

/api/v1/ml/training-data

Dados prontos para anÃ¡lise/modelagem local.

ğŸ“ˆ PrediÃ§Ã£o Online
/api/v1/ml/predictions: permite enviar novos dados e receber prediÃ§Ãµes em tempo real.

ğŸ” AtualizaÃ§Ã£o do Modelo
Re-treinamento automÃ¡tico com atualizaÃ§Ã£o do CSV.

Futuro: integraÃ§Ã£o CI/CD para automaÃ§Ã£o do deploy de modelos.

ğŸ”Œ 5. Plano de IntegraÃ§Ã£o com Modelos de ML
ğŸ¯ Treinamento
Script data_model.py treina e salva o modelo.

Pode ser agendado (cron, Airflow).

ğŸ§  PrediÃ§Ã£o
Modelo carregado na inicializaÃ§Ã£o da API.

PrediÃ§Ãµes servidas via REST.

ğŸ“Š Monitoramento
MÃ©tricas de performance expostas via endpoint.

Logs de prediÃ§Ã£o armazenados para anÃ¡lise de drift.

ğŸš€ 6. Futuras EvoluÃ§Ãµes
ğŸ“¦ Migrar dados para banco relacional (PostgreSQL) ou NoSQL (MongoDB)

ğŸ› ï¸ Orquestrar scraping/processamento com Airflow

ğŸ¤– Servir modelo com FastAPI, BentoML ou Seldon

ğŸ” Adicionar autenticaÃ§Ã£o OAuth2, rate limiting, cache com Redis

â˜ï¸ Deploy em nuvem (AWS, Azure, GCP) com CI/CD
