
 ğŸ§  Projeto de Pipeline de Machine Learning com API Flask

Este projeto demonstra a construÃ§Ã£o de um pipeline completo de Machine Learning, desde a coleta de dados com Web Scraping atÃ© o consumo de prediÃ§Ãµes via API Flask.

---

## ğŸ“Š 1. Diagrama de Pipeline

```
flowchart TD
    A[ğŸ“¥ IngestÃ£o de Dados (Web Scraping)] --> B[ğŸ—‚ï¸ Armazenamento CSV]
    B --> C[ğŸ§¹ PrÃ©-processamento & UnificaÃ§Ã£o (Pandas)]
    C --> D[ğŸš€ API Flask]
    D --> E[ğŸŒ Consumo por Frontend, Cientistas de Dados, Apps]
    C --> F[ğŸ¤– Modelo de ML (Treinamento/PrediÃ§Ã£o)]
    F --> D
```
    
---

## ğŸ§¾ 2. DescriÃ§Ã£o do Pipeline

### ğŸ“¥ IngestÃ£o  
- Dados coletados via Web Scraping de um site de livros.  
- Armazenamento em arquivos `.csv` no diretÃ³rio `exports/csv/`.

### ğŸ”„ Processamento  
- UnificaÃ§Ã£o dos arquivos CSV e prÃ©-processamento com Pandas.  
- GeraÃ§Ã£o do arquivo `tabela_unificada.csv`.  
- Limpeza de dados, tratamento de tipos e codificaÃ§Ã£o de variÃ¡veis categÃ³ricas.

### ğŸš€ API  
A API Flask expÃµe os seguintes endpoints RESTful:

- ğŸ” **Consulta e busca**
- ğŸ“Š **EstatÃ­sticas**
- ğŸ” **AutenticaÃ§Ã£o (JWT)**
- ğŸ¤– **PrediÃ§Ã£o com modelo ML**

### ğŸ¤– Machine Learning  
- Treinamento de um modelo **RandomForest** para prever o `rating` dos livros.  
- ExposiÃ§Ã£o do modelo via endpoint: `/api/v1/ml/predictions`.

### ğŸŒ Consumo  
- Cientistas de dados, aplicaÃ§Ãµes web/mobile e dashboards podem consumir a API para anÃ¡lises, visualizaÃ§Ãµes ou automaÃ§Ãµes.

---

## ğŸ—ï¸ 3. Arquitetura para Escalabilidade

### ğŸ§© SeparaÃ§Ã£o de Responsabilidades  
- MÃ³dulos independentes: scraping, processamento, API, ML.  
- FÃ¡cil manutenÃ§Ã£o e escalabilidade.

### ğŸ—ƒï¸ PersistÃªncia  
- Dados armazenados em CSVs, com possibilidade futura de migraÃ§Ã£o para PostgreSQL ou MongoDB.  
- Modelos versionados em disco (futuramente para S3, MLflow, etc).

### âš™ï¸ API Stateless  
- Flask pode ser servido por Gunicorn ou UWSGI atrÃ¡s de um Nginx.  
- Suporte a escalabilidade horizontal (Docker, Kubernetes).

### ğŸ§  ML como ServiÃ§o  
- Modelo ML exposto como microserviÃ§o (ex: FastAPI, BentoML).  
- Possibilita re-treinamento e versionamento independentes.

---

## ğŸ‘¨â€ğŸ”¬ 4. CenÃ¡rio de Uso para Cientistas de Dados/ML

### ğŸ“‚ Acesso aos Dados  
Endpoints:

- `/api/v1/ml/features`
- `/api/v1/ml/training-data`

Permitem acesso aos dados prontos para anÃ¡lise e modelagem local.

### ğŸ“ˆ PrediÃ§Ã£o Online  
- Endpoint `/api/v1/ml/predictions`: permite envio de dados e retorno da prediÃ§Ã£o em tempo real.

### ğŸ” AtualizaÃ§Ã£o do Modelo  
- Re-treinamento automÃ¡tico a partir dos CSVs.  
- Futuro: CI/CD para automaÃ§Ã£o do deploy de modelos.

---

## ğŸ”Œ 5. Plano de IntegraÃ§Ã£o com Modelos de ML

### ğŸ¯ Treinamento  
- Script `data_model.py` realiza o treinamento e salva o modelo.  
- Pode ser agendado com `cron`, `Airflow`, etc.

### ğŸ§  PrediÃ§Ã£o  
- Modelo carregado na inicializaÃ§Ã£o da API.  
- PrediÃ§Ãµes via requisiÃ§Ãµes REST.

### ğŸ“Š Monitoramento  
- ExposiÃ§Ã£o de mÃ©tricas de performance por endpoint.  
- Logs de prediÃ§Ãµes armazenados para anÃ¡lise de *model drift*.

---

## ğŸš€ 6. Futuras EvoluÃ§Ãµes

- ğŸ“¦ Migrar dados para banco relacional (PostgreSQL) ou NoSQL (MongoDB)  
- ğŸ› ï¸ Orquestrar scraping e processamento com Apache Airflow  
- ğŸ¤– Servir modelo com FastAPI, BentoML ou Seldon  
- ğŸ” Adicionar autenticaÃ§Ã£o OAuth2, rate limiting e cache com Redis  
- â˜ï¸ Deploy em nuvem (AWS, Azure, GCP) com integraÃ§Ã£o CI/CD  

---

## ğŸ“Œ ReferÃªncias

- Flask: [https://flask.palletsprojects.com/](https://flask.palletsprojects.com/)  
- Scikit-learn: [https://scikit-learn.org/](https://scikit-learn.org/)  
- JWT: [https://jwt.io/](https://jwt.io/)

---
